\documentclass[a4paper,justified]{tufte-handout}

%\geometry{showframe}% for debugging purposes -- displays the margins

% For A4 paper
\geometry{
  left=14.8mm, % left margin
  %right=30.8mm, % right margin
  textwidth=120mm, % main text block
  marginparsep=3.5mm, % gutter between main text block and margin notes
  marginparwidth=45.4mm % width of margin notes
}

\usepackage{amsmath}
\usepackage{hyperref}

% Set up the images/graphics package
\usepackage{graphicx}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
\graphicspath{{graphics/}}

\title{Trigger-object Level Analysis with the ATLAS detector at the Large Hadron Collider: summary and perspectives.}
\author[Experiment]{Antonio Boveia$^1$, Caterina Doglioni$^2$, William Kalderon$^2$, Frank Winklmeier$^3$\\
(1) The Ohio State University (2) Lund University (3) University of Oregon}
%\date{09 December 2016}  % if the \date{} command is left out, the current date will be used

\fancyhf{} % Can make a shorter running head
\fancyhead[LE]{\textsc{\thepage}}
\fancyhead[RE]{\textsc{Trigger-object Level Analysis in ATLAS}} 
\fancyhead[LO]{\textsc{A. Boveia, C. Doglioni, W. Kalderon, F. Winklmeier}} 
\fancyhead[RO]{\thepage} 


% The following package makes prettier tables.  We're all about the bling!
\usepackage{booktabs}
\usepackage{wrapfig}
% The units package provides nice, non-stacked fractions and better spacing
% for units.
\usepackage{units}

% The fancyvrb package lets us customize the formatting of verbatim
% environments.  We use a slightly smaller font.
\usepackage{fancyvrb}
\fvset{fontsize=11pt}

% Small sections of multiple columns
\usepackage{multicol}

% Provides paragraphs of dummy text
\usepackage{lipsum}

% These commands are used to pretty-print LaTeX commands
\newcommand{\doccmd}[1]{\texttt{\textbackslash#1}}% command name -- adds backslash automatically
\newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
\newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
\newenvironment{docspec}{\begin{quote}\noindent}{\end{quote}}% command specification environment
\newcommand{\docenv}[1]{\textsf{#1}}% environment name
\newcommand{\docpkg}[1]{\texttt{#1}}% package name
\newcommand{\doccls}[1]{\texttt{#1}}% document class name
\newcommand{\docclsopt}[1]{\texttt{#1}}% document class option name


\begin{document}

%\begin{fullwidth}

\maketitle% this prints the handout title, author, and date


\begin{fullwidth}
\vspace{-10px}

\begin{abstract}
%BK: as of now it is only a placeholder, moved here the old summary/conclusion. 

%The research theme of the selected projects should involve e-science method development with a connection to strategic computational applications. 

\noindent This document summarizes the motivations, challenges and perspectives on the Trigger-object Level Analysis (TLA) in ATLAS, focusing on the case where the objects are hadronic jets. It is intended as a complement to the HEP Software Foundation Community Whitepaper on trigger and reconstruction. 
\end{abstract}

\end{fullwidth}

\tableofcontents

\section{Introduction}\label{sec:introduction}

Searches for the small signals produced by weakly-interacting physics require novel triggering strategies to extract them from copious backgrounds. The data rate delivered by the LHC (more than 30 million collisions per second during 2015) far exceeds ATLAS's capabilities for recording events offline. For this reason, the ATLAS trigger system discards data from most of the collisions that occur, selecting events for later analysis based on the presence of high transverse momentum physics objects (muons, electrons, photons, jets, tau leptons and missing transverse momentum). It is a crucial component of the experiment, responsible for an irrevocable decision about what data the experiment collects. 

The bandwidth available to the trigger system is ultimately limited by the amount of data that can be recorded to offline storage. For some final states, e.g. those containing leptons, events containing objects with low transverse momentum thresholds can be retained due to the relatively low backgrounds at a hadron collider. For final states containing jets, taus and missing transverse momentum, the event rates are large and grow rapidly with the number of simultaneous proton-proton interactions. The large background rates make it difficult to retain events involving physics processes with energies below the TeV, around the electroweak scale. 

The electroweak scale is a crucial energy scale of the Standard Model. It has been extensively probed at the LEP experiments especially in processes involving leptons. The LHC can proceed with an exhaustive study in all final states, in its programme of data delivery spanning from the current data taking period (Run 2) to the data taking period after the machine's major upgrades (HL-LHC).  However, the increase of background rates from Quantum ChromoDynamics (QCD) prevents the study of physics at the electroweak scale in all final states. This penalizes signatures that contain exclusively hadronic objects, at the last collider opportunity for the direct discovery of weakly interacting  particles below the TeV~\cite{Dobrescu:2013cmh}. 

These constraints are overcome through the implementation of the novel real-time data analysis techniques called Data Scouting in CMS and Trigger-object Level Analysis (TLA) in ATLAS. Only a fraction of the full event is saved and used in these searches, allowing the recording of far more events than otherwise possible. 

This technique requires that the algorithms used to reconstruct these objects are fast and do not contribute significantly to the overall trigger latency, so that they can make use of a small fraction of the existing resources. It also requires that the performance of objects at the trigger level is comparable to that of objects after the full set of calibration and reconstruction, so that only a small set of information is stored for further analysis. A successful TLA requires that the overall ATLAS trigger system performs at its best even in the conditions of numerous multiple proton-proton interactions foreseen for the HL-LHC, and it provides a strong motivation to improve the trigger system and the reconstruction of hadronic objects for the benefit of the entire experiment.

In this document, we use the search for low-mass dijet resonances as an example of an analysis using the TLA technique. The dijet TLA was implemented in ATLAS~\cite{ATLAS-CONF-2016-030} and CMS~\cite{Khachatryan:2016ecr} starting with the 2015 and 2012 LHC datasets, respectively. We present challenges and improvements to these searches, pertaining to both hardware and software trigger. 

Dijet resonance searches at hadron colliders have a long history, owing to the large number of new physics models that predict them. During the LHC Run-1 and at earlier colliders, these searches focused on the discovery of new particles at the highest partonic center-of-mass energies that the collider could produce. Dijet resonance searches at multi-TeV masses are highly sensitive to certain types of dark matter mediators~\cite{Abercrombie:2015wmb,Chala:2015ama}.

Dijet resonance searches at sub-TeV masses remain equally well-motivated. For example, light dark matter mediators may have very weak couplings to partons and still easily reproduce the observed cosmological dark matter density in standard thermal cosmological histories~\cite{Chala:2015ama}. However, prior experiments were unable to probe sufficiently weak couplings with their relatively small datasets, and even couplings of order unity are not probed in the full mass range around the EW scale. The LHC will produce orders of magnitude more data than previous experiments, which will provide much greater reach  for these little-explored sub-TeV dijet resonances which are rarely produced. These data can be fully exploited using a TLA, assuming that adequate jet calibration techniques are in place. %pile-up mitigation techniques are in place. 

In this document, we outline the ATLAS trigger system and the limitations of a TLA in terms of First-Level trigger (L1)  and High Level Trigger (HLT). We then focus on the performance needs for such a search, and finally conclude with near and far-future upgrades to the calibration scheme. 

\section{Selecting events: Level-1 limitations for a jet TLA} \label{sec:L1Limitations}

The ATLAS trigger system at the LHC Run 2 is implemented in two levels, a hardware first level (L1) and a software High Level Trigger (HLT)~\cite{Aaboud:2016leb}.

To identify events containing hadronic jets, the L1 trigger constructs regions of interest (jet ROIs) in the calorimeter from $ \delta\eta \times \delta\phi$ = 0.2 $\times$ 0.2 calorimeter segments using a sliding window algorithm. Because the L1 decision must be taken rapidly, there are no jet-level energy corrections applied to those regions of interest. During the LHC Run 2, the L1 accepts events at a rate of 100 kHz. After the HL-LHC upgrades, the ATLAS trigger could foresee a three-level design (Level Zero, L1 and HLT)  where the first of these levels can accept events at a rate of 1 MHz. 

Events accepted by the hardware trigger are then processed further by the HLT. A Trigger-object-Level Analysis (TLA) reuses these objects reconstructed at the HLT, whose algorithms are only executed if the L1 condition is satisfied. This is a hard limitation for probing low-mass objects, as the L1 will only select events above a certain transverse momentum threshold. The algorithms reconstructing L1 objects are very coarse-grained, due to the time constraints imposed by the LHC bunch crossing. Since the energy resolution of L1 jets is much worse than the resolution of HLT jets, many of the events recorded fall outside the interesting dijet mass region, and are not usable for a TLA. If the reconstruction and calibration of L1 objects could be improved, it would be to the benefit of searches for low-mass mediators decaying into jets, as the allocated event rate for hadronic L1 triggers could be used more efficiently. 

The application of lookup table-based calibration constants can be foreseen directly at the hardware level, even during the course of the LHC Run-3. At the HL-LHC, more finely grained information will be available at the L1. With substantial additional capacity added to the global trigger processor for the HL-LHC and with improved hardware, it will be possible to assemble jet trigger data for the entire calorimeter at the first level of the trigger, rather than just in narrow regions of interest. Combined with dedicated calibrations, this feature will allow significant improvements in the resolution of L1 objects and employ fast calorimeter-based techniques to reject pile-up and select interesting events from decays of boosted objects. 
\section{Performance of a TLA: reconstruction and calibration at the HLT} \label{sec:HLTPerformance}

In a TLA, the goal is to reduce statistical uncertainties on the background events to a negligible level. Systematic uncertainties on the background estimation for TLA dijet searches are minimized by estimating the background through a data-driven fit to the smooth dijet mass distribution that does not allow for localized excesses. The use of a smooth description for the background estimation strictly relies on the absence of features arising from either detector malfunctioning or calibration. For this reason, the performance of the calibration of HLT jets is crucial for a TLA searching for low-mass hadronic resonances. This is especially in an environment such as the HL-LHC, where the effects of multiple proton-proton interactions will significantly affect the energy scale and resolution of jets from the resonance decays. 

\subsection{Current reconstruction and calibration procedure for trigger jets}
\label{subsec:L1Limitations}


The reconstruction of HLT jets (also called trigger jets) is kept as close as possible to the full reconstruction. Dedicated calibrations are applied to these partially recorded events, making the properties of jets reconstructed at the HLT comparable to those of jets reconstructed from full events. These calibrations account for differences between fully recorded jets as well as for missing information from detectors other than the calorimeters. In the case of jets during the first part of Run-2, only calorimeter information is available to the HLT for jet reconstruction and calibration. 

In the HLT, groups of contiguous calorimeter cells (topological clusters) are formed based on the significance of the energy deposit over calorimeter noise~\cite{Aad:2016upy}. This step is the most time-consuming in the jet reconstruction chain, with an average time of 98 ms per event with 40 simultaneous interactions. Topological clusters are then themselves clustered into jets using the anti-kt algorithm~\cite{Cacciari:2008gp,Cacciari:2006} with distance parameter R = 0.4. The HLT decision is taken on the basis of the transverse energy of trigger jets. 

For fully reconstructed jets, the calibration procedure includes a number of steps~\cite{Aaboud:2017jcu}. The first calibration step removes the additional energy added to the jet from multiple proton-proton interactions, based on the area of the jet and on the energy density of the event. A further calibration step, derived from simulated data, on average restores the full hadronic energy of the jet. It is followed by another simulation-based correction using multiple detector inputs (including tracks) to improve the resolution of the jet energy measurement. Data-derived corrections are applied next, based on a number of balancing techniques (forward jet balanced against a central jet, a photon or a number of other jets). These final calibration steps correct for the miscalibration that would occur in simulation-based calibration steps, if the the detector conditions were not modelled correctly in simulation. 

Currently, only  the initial pile-up correction and the basic jet energy scale correction derived from simulation are applied to HLT jets in real-time. If tracks were available, a correction exploiting the fragmentation differences between quark- and gluon-initiated jets (the Global Sequential Correction in~\cite{ATLAS-CONF-2015-002}) could  be applied in real-time and bring a significant improvement in the dijet mass resolution, since the fluctuations due to the different calorimeter response for these two kinds of jets would be greately reduced. This in turn would lead to a sharper signal peak atop a falling background distribution and increase the sensitivity of this search. Likewise, the jets used in the analysis could benefit from the application of data-derived corrections, especially those equalizing the jet energy response across the detector geometry. 

Applying a correction to equalize the energy response across the detectors would benefit from a quasi-real-time calibration of the data, in case calorimeters or machine conditions changed. The data would first be used to derive the information necessary for the correction, so that the correction could be applied to the current and subsequent dataset. Such a calibration would initially only be used as a cross-check when derived with a small amount of data, but its precision would improve as more data is taken. In a calibration loop, it  would also be possible to apply a correction that fully restores the performance of HLT jets to that of offline jets, using the ratio of the energies of trigger jets and fully reconstructed jets in events selected by the HLT. Every step of this calibration would be thoroughly tested and automatized before being deployed at the HLT. 

Another use case for a calibration loop such as described above is providing calibration constants to offline jets with much larger statistics. This may allow a reduction in the rates of calibration triggers (at the present moment 10\% of the total jet trigger bandwidth), if those triggers are not in use for other purposes.

\subsection{Pile-up subtraction}

The average number of simultaneous proton-proton interactions in the LHC Run-1 and Run-2 is 40.  At the HL-LHC, this number will grow to 200. This pile-up affects the energy of interesting, hard scatter jets, and adds extra reconstructed jets to the events stemming from the secondary interactions. The trigger system, especially in the case of a TLA searching for low-mass hadronic resonances, plays a crucial role in the rejection of events that would be selected due to spurious jets. 

If tracking information is available, fast algorithms~\cite{ATLAS:2017pfq,Bertolini:2014bba,Cacciari:2014gra} can be employed to correct for the additional energy and reject pile-up jets. During the course of  Run-2 and Run-3, ATLAS plans to use the newly installed Fast TracKer (FTK) trigger processor. The FTK  trigger processor will perform rapid, high-quality charged-particle tracking throughout the entire ATLAS silicon detector within 25 Î¼s of every Level-1 trigger decision~\cite{1748-0221-7-10-C10002,Shochet:2013gaw}.  Using massively parallel pattern recognition hardware, the FTK will find all tracks with transverse momentum above 1 GeV that traverse the entire silicon detector, with parameter measurements that are close to that of offline track reconstruction. The FTK augments existing software tracking that can be run only on a small, narrowly-defined set of regions of interest, making high quality tracking available throughout the ATLAS High Level Trigger and freeing scarce processing time for more sophisticated trigger-decision-making. At the HL-LHC, ATLAS will employ a fully-fledged track trigger providing detailed high-quality tracking information. 

Further work on algorithms applied both at the jet constituent and the jet level will be needed, as the time required by current algorithms to consider all tracks in the event will be large.  In this context, common infrastructure across the LHC collaborations could be sought for reconstruction and pile-up subtraction software that considers tracks at the trigger level. 
The installation of track triggers and timing detectors~\cite{1748-0221-6-12-C12065,Martelli:2017qbe,Cerri:2016lgm,McCarthy:2016pzc} at the HL-LHC will remove the effects of multiple interactions using track information at the HLT, and significantly improve the jet energy resolution. This is a crucial advancement needed to gain access to lower mass resonances with trigger objects at the HL-LHC, and paves the way for real-time analysis with other physics objects such as photons and missing transverse momentum that are also used in dark matter searches. This will not affect the data size that is the prerequisite of TLAs, as the information necessary for applying such a calibration does not need to be stored. 

\section{Conclusions and outlook}

The LHC data taking campaign at a center of mass of 13 fb-1 has just begun. However, accessing rare processes with the full Run-2 and Run-3 300 fb-1 dataset will be far more challenging, since this large data set comes at the cost of many multiple proton-proton interactions (pile-up) and of stricter constraints on the minimum transverse momentum thresholds imposed for recording full events. Trigger Level Analyses can be employed as a strategy to enhance the physics output for dijet resonance searches at the LHC in these harsh conditions, and across the full range of physics considered by the experiment. At the HL-LHC, TLAs can also take advantage of major upgrades to the ATLAS trigger system, such as the introduction of track triggers and real-time calibration techniques. 
 
The performance of objects built using the minimal amount of information from the trigger systems must be continuously improved now and for the ATLAS upgrades, in order to search for lower-rate and lower-momentum processes.
 
The main improvements that can be foreseen for the purpose of a dijet TLA are:

\begin{itemize}
\item A more finely grained L1 object calibration, implemented at the hardware level, which could pave the way for TLAs to be performed at the L1;
\item The inclusion of tracking and timing at the trigger level, for pile-up suppression and reduction of quark/gluon response differences;
\item An improved HLT calibration done before the HLT events are used or recorded.
\end{itemize}

 It is also desirable to extend the TLA technique to other physics objects, so that photons and muons can be identified and calibrated in real-time in order to store only high-level information in partially reconstructed events. This will allow the extension of LHC Dark Matter searches to be sensitive to even lighter resonances, see e.g. Ref.~\cite{Mariotti:2017vtv}, and provide essential cross-checks to e.g. the LHCb new physics program using muon events~\cite{Ilten:2016tkc}.
 
 \section*{Acknowledgements}
 
 We thank Andrew Pilkington, Steven Schramm, Peter Sherwood, Teng Jian Khoo, David Strom and Anna Sfyrla for inputs and discussion.



\clearpage

\bibliography{CWP-ATLAS-TLA}
%\nobibliography
\bibliographystyle{plain}

\end{document}
